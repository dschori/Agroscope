{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow, imread, imsave, figure\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import rescale, resize\n",
    "\n",
    "\n",
    "#Keras:\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "#Custom Functions:\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "sys.path.append(ROOT_DIR)\n",
    "\n",
    "from imports.utils.log_progress import log_progress\n",
    "from imports.utils.visualization import Visualize\n",
    "from imports.utils.enums import DATA_BASE_PATH, SHAPE\n",
    "from imports.models.u_net import get_unet\n",
    "from imports.utils.utils import rle_encode, rle_decode\n",
    "\n",
    "DATA_IMAGE_PATH = DATA_BASE_PATH + '/Images'\n",
    "DATA_MASK_PATH = DATA_BASE_PATH + '/Masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training Samples: 354\n",
      "Number of validation Samples: 102\n",
      "Number of test Samples: 51\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_pickle(DATA_BASE_PATH+'/train_df')\n",
    "val_df = pd.read_pickle(DATA_BASE_PATH+'/val_df')\n",
    "test_df = pd.read_pickle(DATA_BASE_PATH+'/test_df')\n",
    "\n",
    "print(\"Number of training Samples:\", len(train_df))\n",
    "print(\"Number of validation Samples:\", len(val_df))\n",
    "print(\"Number of test Samples:\", len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Description | a |\n",
    "|------|------|--|\n",
    "|   a  | table| a|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports.models.losses import bce_dice_loss, dice_coeff\n",
    "from keras.models import load_model, model_from_json\n",
    "\n",
    "import keras.losses\n",
    "keras.losses.custom_loss = bce_dice_loss\n",
    "\n",
    "model = load_model('../saved_models/unet/unet1024_80epochs_circle.h5', custom_objects={'bce_dice_loss': bce_dice_loss,'dice_coeff':dice_coeff})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
